{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee605671",
   "metadata": {},
   "source": [
    "## Music genre classification using spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "\n",
    "# Mount Google Drive to access data\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# defining the local path to google drive\n",
    "images_path = f'/content/drive/MyDrive/images_original'\n",
    "\n",
    "\n",
    "if not os.path.exists(images_path):\n",
    "    \n",
    "    images_path = f'/content/drive/MyDrive/images_original'\n",
    "\n",
    "    if not os.path.exists(images_path):\n",
    "        raise FileNotFoundError(f'Directory not found: {images_path}')\n",
    "\n",
    "\n",
    "\n",
    "# Transforming the images, as per requirement\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((180, 180)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Creating an Imagefolder dataset, to use throughout the project\n",
    "dataset = datasets.ImageFolder(root=images_path, transform=transform)\n",
    "\n",
    "# Creating a DataLoader for batching and shuffling the data\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# cross checking the number of classes present in dataset\n",
    "num_classes = len(dataset.classes)\n",
    "class_names = dataset.classes\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"Class names:\", class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa378b",
   "metadata": {},
   "source": [
    "## Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Specifying the sizes for training, validation, and test sets\n",
    "total_samples = len(dataset)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.2 * total_samples)\n",
    "test_size = test_size = total_samples - train_size - val_size\n",
    "\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Creating DataLoaders for each split\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9489d",
   "metadata": {},
   "source": [
    "## Fully connectional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d551f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Defining the Fully Connected Network\n",
    "class FullyConnectedNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FullyConnectedNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# setting the Hyperparameters\n",
    "input_size = 180 * 180 * 3 \n",
    "hidden_size = 128\n",
    "num_classes = 10  \n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs_50 = 50\n",
    "num_epochs_100 = 100\n",
    "\n",
    "# Creating the model, loss function, and optimizer\n",
    "model_50 = FullyConnectedNetwork(input_size, hidden_size, num_classes)\n",
    "model_100 = FullyConnectedNetwork(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_50 = optim.Adam(model_50.parameters(), lr=learning_rate)\n",
    "optimizer_100 = optim.Adam(model_100.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Training the model for 50 epochs\n",
    "for epoch in range(num_epochs_50):\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model_50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer_50.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_50.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_50}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Training the model for 100 epochs\n",
    "for epoch in range(num_epochs_100):\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model_100(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer_100.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_100.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_100}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Evaluation on validation set\n",
    "\n",
    "model_50.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model_50(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_1 = correct / total\n",
    "print(f'Validation Accuracy for 50 epochs: {accuracy_1 * 100:.2f}%')\n",
    "\n",
    "model_100.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model_100(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_2 = correct / total\n",
    "print(f'Validation Accuracy for 100 epochs: {accuracy_2 * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4451821",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Defining a Convolutional Neural Network\n",
    "class ModifiedConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedConvolutionalNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1_1 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1_1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2_1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2_1 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 45 * 45, 512)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu1_1(self.conv1_1(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.relu2_1(self.conv2_1(x))\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu_fc(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# defining the Hyperparameters\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 23\n",
    "num_epochs = 50\n",
    "\n",
    "# Creating the model, loss function, and optimizer\n",
    "modified_model = ModifiedConvolutionalNetwork(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modified_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Creating DataLoader for training\n",
    "modified_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in modified_train_loader:\n",
    "        outputs = modified_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Final evaluation on the validation set\n",
    "modified_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = modified_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_modified_model = correct / total\n",
    "print(f'Validation Accuracy with Modified Model: {accuracy_modified_model * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de4df69",
   "metadata": {},
   "source": [
    "## Convolutional neural network with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define a Convolutional Neural Network with Batch Normalization\n",
    "class ModifiedConvolutionalNetworkWithBatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedConvolutionalNetworkWithBatchNorm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1_1 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(32)\n",
    "        self.relu1_1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2_1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(64)\n",
    "        self.relu2_1 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 45 * 45, 512)\n",
    "        self.bn_fc = nn.BatchNorm1d(512)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu1_1(self.bn1_1(self.conv1_1(x)))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.relu2_1(self.bn2_1(self.conv2_1(x)))\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu_fc(self.bn_fc(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# defining Hyperparameters\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 23\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the model, loss function, and optimizer\n",
    "modified_model_with_bn = ModifiedConvolutionalNetworkWithBatchNorm(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modified_model_with_bn.parameters(), lr=learning_rate)\n",
    "\n",
    "modified_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in modified_train_loader:\n",
    "        outputs = modified_model_with_bn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Final evaluation on the validation set\n",
    "modified_model_with_bn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = modified_model_with_bn(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_modified_model_with_bn = correct / total\n",
    "print(f'Validation Accuracy with Modified Model and Batch Normalization: {accuracy_modified_model_with_bn * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2daa693",
   "metadata": {},
   "source": [
    "## Convolutional neural network with RMSprop optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define a modified Convolutional Neural Network with Batch Normalization\n",
    "class ModifiedConvolutionalNetworkWithBatchNorm(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ModifiedConvolutionalNetworkWithBatchNorm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1_1 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(32)\n",
    "        self.relu1_1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2_1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(64)\n",
    "        self.relu2_1 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 45 * 45, 512)\n",
    "        self.bn_fc = nn.BatchNorm1d(512)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu1_1(self.bn1_1(self.conv1_1(x)))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = self.relu2_1(self.bn2_1(self.conv2_1(x)))\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu_fc(self.bn_fc(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 23\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the model, loss function, and optimizer (RMSprop)\n",
    "modified_model_with_bn = ModifiedConvolutionalNetworkWithBatchNorm(num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(modified_model_with_bn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create DataLoader for training\n",
    "modified_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in modified_train_loader:\n",
    "        outputs = modified_model_with_bn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Final evaluation on the validation set\n",
    "modified_model_with_bn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = modified_model_with_bn(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy_modified_model_with_bn = correct / total\n",
    "print(f'Validation Accuracy with Modified Model and Batch Normalization: {accuracy_modified_model_with_bn * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
